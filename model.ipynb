{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7V-2NzQcBflB","executionInfo":{"status":"ok","timestamp":1670548727512,"user_tz":360,"elapsed":7962,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}}},"outputs":[],"source":["import pandas as pd\n","import os\n","import torch\n","from torch import nn, optim\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from tqdm import trange\n","\n","train_size = 12\n","predict_size = 4"]},{"cell_type":"markdown","source":["Import Data file"],"metadata":{"id":"2cSd1VZjBiV_"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"9KNEKm1fBflE","executionInfo":{"status":"ok","timestamp":1670548786212,"user_tz":360,"elapsed":1449,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}}},"outputs":[],"source":["# for local environment\n","# df = pd.read_pickle('working_dataset.pkl')\n","\n","# for cloud environment\n","df = pd.read_csv('https://drive.google.com/uc?export=download&id='\n"," + '12fztRILR7EaGV-ipq_89AEAZAFUlyjUx')\n","\n","data = df.iloc[:, 1:].values.astype(float)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-G2aJxKIBflF","executionInfo":{"status":"ok","timestamp":1670548791640,"user_tz":360,"elapsed":354,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40dccf61-4019-4654-aafb-d25cf6c72771"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1526, 12, 14), (1526, 4))"]},"metadata":{},"execution_count":3}],"source":["# define the prediction be the % change of the prices\n","price_pct = [0]\n","for i in range(1, data.shape[0]):\n","    price_pct.append((data[i, 1] - data[i-1, 1])/data[i-1, 1])\n","price_pct = np.array(price_pct, dtype=float)\n","prices = data[:, 1].copy()\n","data[:, 1] = price_pct\n","\n","# normalize the featres\n","normalized_features = MinMaxScaler().fit_transform(data[:, 2:])\n","X = np.hstack((normalized_features, np.array(price_pct).reshape(-1, 1)))\n","X = np.array([X[i-train_size:i, :] for i in range(train_size, len(data)-predict_size)], dtype=np.float64)\n","y = np.array([price_pct[i:i+predict_size] for i in range(train_size, len(data)-predict_size)], dtype=np.float64)\n","\n","X.shape, y.shape"]},{"cell_type":"markdown","source":["Build up the learning model"],"metadata":{"id":"HJ5z8KwQBk7r"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"ecbYe0cqBflI","executionInfo":{"status":"ok","timestamp":1670548809496,"user_tz":360,"elapsed":255,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}}},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self,hidden_size=32,num_layers=2,dropout=0.2):\n","        super(Model, self).__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=14,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout,\n","        )\n","        self.fc = nn.Linear(hidden_size, 4)\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n","        \n","        _, (hn, _) = self.lstm(x, (h0, c0))\n","        out = self.fc(hn[0])\n","        return out"]},{"cell_type":"markdown","source":["Devide The dataset into training, validating, and Testing."],"metadata":{"id":"VU5Px5_XBnc1"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"hK4AJNY-BflK","executionInfo":{"status":"ok","timestamp":1670548812213,"user_tz":360,"elapsed":203,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}}},"outputs":[],"source":["train_X, train_y = X[:int(0.6 * len(X))], y[:int(0.6 * len(y))]\n","valid_X, valid_y = X[int(0.6 * len(X)):int(0.8 * len(X))], y[int(0.6 * len(y)):int(0.8 * len(y))]\n","test_X, test_y = X[int(0.8 * len(X)):], y[int(0.8 * len(y)):]"]},{"cell_type":"markdown","source":["Applying Adam optimizer (minibatch) onto learning model"],"metadata":{"id":"QiHoYwBlBpl8"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"0ozudc9oBflK","executionInfo":{"status":"ok","timestamp":1670548835479,"user_tz":360,"elapsed":16584,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ca4f671-4c2d-44c6-f1f1-70b153033170"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '3.04e-03', 'valid_loss': '5.78e-04'}\n","{'epoch': 1, 'train_loss': '5.88e-04', 'valid_loss': '5.10e-04'}\n","{'epoch': 2, 'train_loss': '5.31e-04', 'valid_loss': '4.77e-04'}\n","{'epoch': 3, 'train_loss': '4.88e-04', 'valid_loss': '4.56e-04'}\n","{'epoch': 4, 'train_loss': '4.58e-04', 'valid_loss': '4.42e-04'}\n","{'epoch': 5, 'train_loss': '4.37e-04', 'valid_loss': '4.31e-04'}\n","{'epoch': 6, 'train_loss': '4.23e-04', 'valid_loss': '4.21e-04'}\n","{'epoch': 7, 'train_loss': '4.13e-04', 'valid_loss': '4.12e-04'}\n","{'epoch': 8, 'train_loss': '4.07e-04', 'valid_loss': '4.01e-04'}\n","{'epoch': 9, 'train_loss': '4.03e-04', 'valid_loss': '3.90e-04'}\n","{'epoch': 10, 'train_loss': '4.01e-04', 'valid_loss': '3.79e-04'}\n","{'epoch': 11, 'train_loss': '3.98e-04', 'valid_loss': '3.67e-04'}\n","{'epoch': 12, 'train_loss': '3.95e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 13, 'train_loss': '3.92e-04', 'valid_loss': '3.44e-04'}\n","{'epoch': 14, 'train_loss': '3.89e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 15, 'train_loss': '3.85e-04', 'valid_loss': '3.28e-04'}\n","{'epoch': 16, 'train_loss': '3.82e-04', 'valid_loss': '3.22e-04'}\n","{'epoch': 17, 'train_loss': '3.79e-04', 'valid_loss': '3.16e-04'}\n","{'epoch': 18, 'train_loss': '3.76e-04', 'valid_loss': '3.12e-04'}\n","{'epoch': 19, 'train_loss': '3.72e-04', 'valid_loss': '3.08e-04'}\n","{'epoch': 20, 'train_loss': '3.69e-04', 'valid_loss': '3.05e-04'}\n","{'epoch': 21, 'train_loss': '3.66e-04', 'valid_loss': '3.02e-04'}\n","{'epoch': 22, 'train_loss': '3.63e-04', 'valid_loss': '3.00e-04'}\n","{'epoch': 23, 'train_loss': '3.60e-04', 'valid_loss': '2.98e-04'}\n","{'epoch': 24, 'train_loss': '3.57e-04', 'valid_loss': '2.97e-04'}\n","{'epoch': 25, 'train_loss': '3.54e-04', 'valid_loss': '2.96e-04'}\n","{'epoch': 26, 'train_loss': '3.52e-04', 'valid_loss': '2.96e-04'}\n","{'epoch': 27, 'train_loss': '3.50e-04', 'valid_loss': '2.96e-04'}\n","{'epoch': 28, 'train_loss': '3.48e-04', 'valid_loss': '2.97e-04'}\n","{'epoch': 29, 'train_loss': '3.47e-04', 'valid_loss': '2.98e-04'}\n","{'epoch': 30, 'train_loss': '3.46e-04', 'valid_loss': '2.99e-04'}\n","{'epoch': 31, 'train_loss': '3.45e-04', 'valid_loss': '3.01e-04'}\n","{'epoch': 32, 'train_loss': '3.44e-04', 'valid_loss': '3.02e-04'}\n","{'epoch': 33, 'train_loss': '3.43e-04', 'valid_loss': '3.04e-04'}\n","{'epoch': 34, 'train_loss': '3.42e-04', 'valid_loss': '3.06e-04'}\n","{'epoch': 35, 'train_loss': '3.42e-04', 'valid_loss': '3.07e-04'}\n","{'epoch': 36, 'train_loss': '3.42e-04', 'valid_loss': '3.09e-04'}\n","best score = 2.96e-04\n"]}],"source":["model = Model()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Apply fullbatch with the adam optimizer"],"metadata":{"id":"fzgJL1b4Br6z"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"6emkoX4QBflN","executionInfo":{"status":"ok","timestamp":1670548927735,"user_tz":360,"elapsed":2075,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de0ac98c-482b-4d85-a60a-14aa90dbed90"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '1.43e-02', 'valid_loss': '1.30e-02'}\n","{'epoch': 1, 'train_loss': '1.20e-02', 'valid_loss': '1.10e-02'}\n","{'epoch': 2, 'train_loss': '9.93e-03', 'valid_loss': '9.21e-03'}\n","{'epoch': 3, 'train_loss': '8.16e-03', 'valid_loss': '7.66e-03'}\n","{'epoch': 4, 'train_loss': '6.63e-03', 'valid_loss': '6.30e-03'}\n","{'epoch': 5, 'train_loss': '5.33e-03', 'valid_loss': '5.13e-03'}\n","{'epoch': 6, 'train_loss': '4.23e-03', 'valid_loss': '4.13e-03'}\n","{'epoch': 7, 'train_loss': '3.31e-03', 'valid_loss': '3.29e-03'}\n","{'epoch': 8, 'train_loss': '2.56e-03', 'valid_loss': '2.60e-03'}\n","{'epoch': 9, 'train_loss': '1.96e-03', 'valid_loss': '2.04e-03'}\n","{'epoch': 10, 'train_loss': '1.50e-03', 'valid_loss': '1.63e-03'}\n","{'epoch': 11, 'train_loss': '1.17e-03', 'valid_loss': '1.35e-03'}\n","{'epoch': 12, 'train_loss': '9.51e-04', 'valid_loss': '1.18e-03'}\n","{'epoch': 13, 'train_loss': '8.40e-04', 'valid_loss': '1.12e-03'}\n","{'epoch': 14, 'train_loss': '8.20e-04', 'valid_loss': '1.15e-03'}\n","{'epoch': 15, 'train_loss': '8.74e-04', 'valid_loss': '1.24e-03'}\n","{'epoch': 16, 'train_loss': '9.76e-04', 'valid_loss': '1.36e-03'}\n","{'epoch': 17, 'train_loss': '1.10e-03', 'valid_loss': '1.46e-03'}\n","{'epoch': 18, 'train_loss': '1.20e-03', 'valid_loss': '1.53e-03'}\n","{'epoch': 19, 'train_loss': '1.27e-03', 'valid_loss': '1.55e-03'}\n","{'epoch': 20, 'train_loss': '1.29e-03', 'valid_loss': '1.52e-03'}\n","{'epoch': 21, 'train_loss': '1.26e-03', 'valid_loss': '1.46e-03'}\n","{'epoch': 22, 'train_loss': '1.19e-03', 'valid_loss': '1.37e-03'}\n","{'epoch': 23, 'train_loss': '1.10e-03', 'valid_loss': '1.27e-03'}\n","best score = 1.12e-03\n"]}],"source":["model_full_batch = Model()\n","\n","optimizer = optim.Adam(model_full_batch.parameters(), lr=0.001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","    output = model_full_batch(torch.from_numpy(train_X).float())\n","    loss = loss_function(output, torch.from_numpy(train_y).float())\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss = loss.item()\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        output = model_full_batch(torch.from_numpy(valid_X).float())\n","        loss = loss_function(output, torch.from_numpy(valid_y).float())\n","        valid_loss = loss.item()\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","\n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Applying Adam optimizer with online learning"],"metadata":{"id":"0J38yNUTCL-z"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"UBCcNJNxBflP","executionInfo":{"status":"ok","timestamp":1670549362967,"user_tz":360,"elapsed":342889,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"def84380-87f1-4e50-d464-5e49b9756b8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '5.85e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 1, 'train_loss': '4.68e-04', 'valid_loss': '3.29e-04'}\n","{'epoch': 2, 'train_loss': '4.51e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 3, 'train_loss': '4.42e-04', 'valid_loss': '3.13e-04'}\n","{'epoch': 4, 'train_loss': '4.34e-04', 'valid_loss': '3.08e-04'}\n","{'epoch': 5, 'train_loss': '4.28e-04', 'valid_loss': '3.09e-04'}\n","{'epoch': 6, 'train_loss': '4.24e-04', 'valid_loss': '3.08e-04'}\n","{'epoch': 7, 'train_loss': '4.21e-04', 'valid_loss': '3.07e-04'}\n","{'epoch': 8, 'train_loss': '4.18e-04', 'valid_loss': '3.04e-04'}\n","{'epoch': 9, 'train_loss': '4.15e-04', 'valid_loss': '3.01e-04'}\n","{'epoch': 10, 'train_loss': '4.12e-04', 'valid_loss': '2.98e-04'}\n","{'epoch': 11, 'train_loss': '4.09e-04', 'valid_loss': '2.95e-04'}\n","{'epoch': 12, 'train_loss': '4.05e-04', 'valid_loss': '2.93e-04'}\n","{'epoch': 13, 'train_loss': '4.01e-04', 'valid_loss': '2.90e-04'}\n","{'epoch': 14, 'train_loss': '3.97e-04', 'valid_loss': '2.88e-04'}\n","{'epoch': 15, 'train_loss': '3.92e-04', 'valid_loss': '2.86e-04'}\n","{'epoch': 16, 'train_loss': '3.87e-04', 'valid_loss': '2.85e-04'}\n","{'epoch': 17, 'train_loss': '3.82e-04', 'valid_loss': '2.84e-04'}\n","{'epoch': 18, 'train_loss': '3.76e-04', 'valid_loss': '2.83e-04'}\n","{'epoch': 19, 'train_loss': '3.71e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 20, 'train_loss': '3.67e-04', 'valid_loss': '2.86e-04'}\n","{'epoch': 21, 'train_loss': '3.57e-04', 'valid_loss': '4.10e-04'}\n","{'epoch': 22, 'train_loss': '3.77e-04', 'valid_loss': '2.81e-04'}\n","{'epoch': 23, 'train_loss': '3.53e-04', 'valid_loss': '3.41e-04'}\n","{'epoch': 24, 'train_loss': '3.66e-04', 'valid_loss': '2.80e-04'}\n","{'epoch': 25, 'train_loss': '3.54e-04', 'valid_loss': '2.80e-04'}\n","{'epoch': 26, 'train_loss': '3.52e-04', 'valid_loss': '2.80e-04'}\n","{'epoch': 27, 'train_loss': '3.51e-04', 'valid_loss': '2.79e-04'}\n","{'epoch': 28, 'train_loss': '3.49e-04', 'valid_loss': '2.76e-04'}\n","{'epoch': 29, 'train_loss': '3.47e-04', 'valid_loss': '2.76e-04'}\n","{'epoch': 30, 'train_loss': '3.44e-04', 'valid_loss': '2.85e-04'}\n","{'epoch': 31, 'train_loss': '3.44e-04', 'valid_loss': '2.88e-04'}\n","{'epoch': 32, 'train_loss': '3.47e-04', 'valid_loss': '2.81e-04'}\n","{'epoch': 33, 'train_loss': '3.42e-04', 'valid_loss': '2.74e-04'}\n","{'epoch': 34, 'train_loss': '3.40e-04', 'valid_loss': '2.75e-04'}\n","{'epoch': 35, 'train_loss': '3.38e-04', 'valid_loss': '2.89e-04'}\n","{'epoch': 36, 'train_loss': '3.41e-04', 'valid_loss': '2.83e-04'}\n","{'epoch': 37, 'train_loss': '3.39e-04', 'valid_loss': '2.78e-04'}\n","{'epoch': 38, 'train_loss': '3.35e-04', 'valid_loss': '2.74e-04'}\n","{'epoch': 39, 'train_loss': '3.34e-04', 'valid_loss': '2.82e-04'}\n","{'epoch': 40, 'train_loss': '3.35e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 41, 'train_loss': '3.34e-04', 'valid_loss': '2.87e-04'}\n","{'epoch': 42, 'train_loss': '3.32e-04', 'valid_loss': '2.79e-04'}\n","{'epoch': 43, 'train_loss': '3.31e-04', 'valid_loss': '2.76e-04'}\n","{'epoch': 44, 'train_loss': '3.30e-04', 'valid_loss': '2.73e-04'}\n","{'epoch': 45, 'train_loss': '3.29e-04', 'valid_loss': '2.73e-04'}\n","{'epoch': 46, 'train_loss': '3.29e-04', 'valid_loss': '2.80e-04'}\n","{'epoch': 47, 'train_loss': '3.28e-04', 'valid_loss': '2.86e-04'}\n","{'epoch': 48, 'train_loss': '3.28e-04', 'valid_loss': '2.83e-04'}\n","{'epoch': 49, 'train_loss': '3.29e-04', 'valid_loss': '2.75e-04'}\n","{'epoch': 50, 'train_loss': '3.24e-04', 'valid_loss': '2.69e-04'}\n","{'epoch': 51, 'train_loss': '3.25e-04', 'valid_loss': '3.01e-04'}\n","{'epoch': 52, 'train_loss': '3.26e-04', 'valid_loss': '3.18e-04'}\n","{'epoch': 53, 'train_loss': '3.27e-04', 'valid_loss': '2.73e-04'}\n","{'epoch': 54, 'train_loss': '3.22e-04', 'valid_loss': '2.76e-04'}\n","{'epoch': 55, 'train_loss': '3.20e-04', 'valid_loss': '3.12e-04'}\n","{'epoch': 56, 'train_loss': '3.24e-04', 'valid_loss': '2.83e-04'}\n","{'epoch': 57, 'train_loss': '3.16e-04', 'valid_loss': '2.76e-04'}\n","{'epoch': 58, 'train_loss': '3.18e-04', 'valid_loss': '3.01e-04'}\n","{'epoch': 59, 'train_loss': '3.18e-04', 'valid_loss': '3.51e-04'}\n","{'epoch': 60, 'train_loss': '3.19e-04', 'valid_loss': '2.88e-04'}\n","best score = 2.69e-04\n"]}],"source":["model_online = Model()\n","\n","optimizer = optim.Adam(model_online.parameters(), lr=0.001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X)):\n","        output = model_online(torch.from_numpy(train_X[i].reshape(1, 12, 14)).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i].reshape(1, 4)).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X))\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 1):\n","            output = model_online(torch.from_numpy(valid_X[i].reshape(1, 12, 14)).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i].reshape(1, 4)).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X))\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Trying different optimizer: SGD."],"metadata":{"id":"RP06tiZACSqP"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"QifV3cW9BflQ","executionInfo":{"status":"ok","timestamp":1670549588420,"user_tz":360,"elapsed":40721,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9894e8f8-e76d-44c2-b21e-e6f033a4c06a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '6.71e-03', 'valid_loss': '5.85e-03'}\n","{'epoch': 1, 'train_loss': '5.68e-03', 'valid_loss': '4.99e-03'}\n","{'epoch': 2, 'train_loss': '4.85e-03', 'valid_loss': '4.30e-03'}\n","{'epoch': 3, 'train_loss': '4.17e-03', 'valid_loss': '3.72e-03'}\n","{'epoch': 4, 'train_loss': '3.60e-03', 'valid_loss': '3.24e-03'}\n","{'epoch': 5, 'train_loss': '3.13e-03', 'valid_loss': '2.84e-03'}\n","{'epoch': 6, 'train_loss': '2.74e-03', 'valid_loss': '2.50e-03'}\n","{'epoch': 7, 'train_loss': '2.41e-03', 'valid_loss': '2.21e-03'}\n","{'epoch': 8, 'train_loss': '2.13e-03', 'valid_loss': '1.97e-03'}\n","{'epoch': 9, 'train_loss': '1.90e-03', 'valid_loss': '1.76e-03'}\n","{'epoch': 10, 'train_loss': '1.70e-03', 'valid_loss': '1.57e-03'}\n","{'epoch': 11, 'train_loss': '1.52e-03', 'valid_loss': '1.42e-03'}\n","{'epoch': 12, 'train_loss': '1.37e-03', 'valid_loss': '1.28e-03'}\n","{'epoch': 13, 'train_loss': '1.25e-03', 'valid_loss': '1.16e-03'}\n","{'epoch': 14, 'train_loss': '1.14e-03', 'valid_loss': '1.06e-03'}\n","{'epoch': 15, 'train_loss': '1.04e-03', 'valid_loss': '9.71e-04'}\n","{'epoch': 16, 'train_loss': '9.55e-04', 'valid_loss': '8.93e-04'}\n","{'epoch': 17, 'train_loss': '8.83e-04', 'valid_loss': '8.24e-04'}\n","{'epoch': 18, 'train_loss': '8.19e-04', 'valid_loss': '7.63e-04'}\n","{'epoch': 19, 'train_loss': '7.64e-04', 'valid_loss': '7.10e-04'}\n","{'epoch': 20, 'train_loss': '7.16e-04', 'valid_loss': '6.64e-04'}\n","{'epoch': 21, 'train_loss': '6.74e-04', 'valid_loss': '6.23e-04'}\n","{'epoch': 22, 'train_loss': '6.38e-04', 'valid_loss': '5.87e-04'}\n","{'epoch': 23, 'train_loss': '6.06e-04', 'valid_loss': '5.56e-04'}\n","{'epoch': 24, 'train_loss': '5.78e-04', 'valid_loss': '5.28e-04'}\n","{'epoch': 25, 'train_loss': '5.54e-04', 'valid_loss': '5.04e-04'}\n","{'epoch': 26, 'train_loss': '5.33e-04', 'valid_loss': '4.83e-04'}\n","{'epoch': 27, 'train_loss': '5.15e-04', 'valid_loss': '4.64e-04'}\n","{'epoch': 28, 'train_loss': '4.99e-04', 'valid_loss': '4.48e-04'}\n","{'epoch': 29, 'train_loss': '4.85e-04', 'valid_loss': '4.34e-04'}\n","{'epoch': 30, 'train_loss': '4.73e-04', 'valid_loss': '4.21e-04'}\n","{'epoch': 31, 'train_loss': '4.63e-04', 'valid_loss': '4.10e-04'}\n","{'epoch': 32, 'train_loss': '4.54e-04', 'valid_loss': '4.00e-04'}\n","{'epoch': 33, 'train_loss': '4.46e-04', 'valid_loss': '3.92e-04'}\n","{'epoch': 34, 'train_loss': '4.39e-04', 'valid_loss': '3.85e-04'}\n","{'epoch': 35, 'train_loss': '4.33e-04', 'valid_loss': '3.78e-04'}\n","{'epoch': 36, 'train_loss': '4.28e-04', 'valid_loss': '3.72e-04'}\n","{'epoch': 37, 'train_loss': '4.23e-04', 'valid_loss': '3.67e-04'}\n","{'epoch': 38, 'train_loss': '4.20e-04', 'valid_loss': '3.63e-04'}\n","{'epoch': 39, 'train_loss': '4.16e-04', 'valid_loss': '3.59e-04'}\n","{'epoch': 40, 'train_loss': '4.14e-04', 'valid_loss': '3.56e-04'}\n","{'epoch': 41, 'train_loss': '4.11e-04', 'valid_loss': '3.53e-04'}\n","{'epoch': 42, 'train_loss': '4.09e-04', 'valid_loss': '3.51e-04'}\n","{'epoch': 43, 'train_loss': '4.07e-04', 'valid_loss': '3.48e-04'}\n","{'epoch': 44, 'train_loss': '4.06e-04', 'valid_loss': '3.46e-04'}\n","{'epoch': 45, 'train_loss': '4.04e-04', 'valid_loss': '3.45e-04'}\n","{'epoch': 46, 'train_loss': '4.03e-04', 'valid_loss': '3.43e-04'}\n","{'epoch': 47, 'train_loss': '4.02e-04', 'valid_loss': '3.42e-04'}\n","{'epoch': 48, 'train_loss': '4.01e-04', 'valid_loss': '3.41e-04'}\n","{'epoch': 49, 'train_loss': '4.01e-04', 'valid_loss': '3.40e-04'}\n","{'epoch': 50, 'train_loss': '4.00e-04', 'valid_loss': '3.39e-04'}\n","{'epoch': 51, 'train_loss': '4.00e-04', 'valid_loss': '3.38e-04'}\n","{'epoch': 52, 'train_loss': '3.99e-04', 'valid_loss': '3.37e-04'}\n","{'epoch': 53, 'train_loss': '3.99e-04', 'valid_loss': '3.37e-04'}\n","{'epoch': 54, 'train_loss': '3.99e-04', 'valid_loss': '3.36e-04'}\n","{'epoch': 55, 'train_loss': '3.98e-04', 'valid_loss': '3.36e-04'}\n","{'epoch': 56, 'train_loss': '3.98e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 57, 'train_loss': '3.98e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 58, 'train_loss': '3.98e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 59, 'train_loss': '3.98e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 60, 'train_loss': '3.98e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 61, 'train_loss': '3.97e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 62, 'train_loss': '3.97e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 63, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 64, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 65, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 66, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 67, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 68, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 69, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 70, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 71, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 72, 'train_loss': '3.97e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 73, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 74, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 75, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 76, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 77, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 78, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 79, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 80, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 81, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 82, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 83, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 84, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 85, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 86, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 87, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 88, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 89, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 90, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 91, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 92, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 93, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 94, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 95, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 96, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 97, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 98, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 99, 'train_loss': '3.97e-04', 'valid_loss': '3.32e-04'}\n"]}],"source":["model = Model()\n","#optimizer = optim.SGD(model.parameters(), lr=0.1)\n","#optimizer = optim.SGD(model.parameters(), lr=0.01)\n","#optimizer = optim.SGD(model.parameters(), lr=0.001)\n","#optimizer = optim.SGD(model.parameters(), lr=0.1,momentum = 0.2,weight_decay= 0.9)\n","#optimizer = optim.SGD(model.parameters(), lr=0.01,momentum = 0.5,weight_decay= 0.9)\n","#optimizer = optim.SGD(model.parameters(), lr=0.001,momentum = 0.8,weight_decay= 0.9)\n","#optimizer = optim.SGD(model.parameters(), lr=0.001,weight_decay= 0.8)\n","#optimizer = optim.SGD(model.parameters(), lr=0.001,weight_decay= 0.85)\n","optimizer = optim.SGD(model.parameters(), lr=0.001,weight_decay= 0.9)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(test_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0"]},{"cell_type":"markdown","metadata":{"id":"ulewfXQGBflS"},"source":["For SGD optimizer, we also tried the learning rate = 0.1, 0.01, 0.001, and 0.0001. Speaking of the result, lr = 0.001 is the best match. The others are either non-convergent or having bigger loss. \n","\n","For SGD optimizer, we also tried weight decay = 0.8, 0.85, and 0.9. Speaking of the result, wd = 0.9 is the best match. The rest of them all generate bigger losses.\n","\n","For SGD optimizer, we also tried momentum = 0, 0.2, 0.5, and 0.8. Speaking of the result, m = 0 is the best one having minimum loss. \n","\n","The best loss gained from SGD is 3.31e-04"]},{"cell_type":"markdown","source":["Testing different optimizer: Adam (With modification of parameters comparing to original used one)"],"metadata":{"id":"LviSWf1JCwaY"}},{"cell_type":"code","source":["model = Model()\n","#optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay= 0.9)\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(test_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 14:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","print(f'best score = {min_loss:.2e}')"],"metadata":{"id":"n28LRlWzCv5C","executionInfo":{"status":"ok","timestamp":1670550381634,"user_tz":360,"elapsed":43065,"user":{"displayName":"Siqi Du","userId":"11358574572773899574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb0d194e-68f6-4f5e-86b7-5dc0606b47d7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '1.15e-02', 'valid_loss': '8.71e-03'}\n","{'epoch': 1, 'train_loss': '4.66e-03', 'valid_loss': '3.80e-03'}\n","{'epoch': 2, 'train_loss': '1.64e-03', 'valid_loss': '1.78e-03'}\n","{'epoch': 3, 'train_loss': '9.38e-04', 'valid_loss': '1.41e-03'}\n","{'epoch': 4, 'train_loss': '8.21e-04', 'valid_loss': '1.29e-03'}\n","{'epoch': 5, 'train_loss': '7.56e-04', 'valid_loss': '1.19e-03'}\n","{'epoch': 6, 'train_loss': '7.04e-04', 'valid_loss': '1.11e-03'}\n","{'epoch': 7, 'train_loss': '6.61e-04', 'valid_loss': '1.04e-03'}\n","{'epoch': 8, 'train_loss': '6.24e-04', 'valid_loss': '9.69e-04'}\n","{'epoch': 9, 'train_loss': '5.94e-04', 'valid_loss': '9.08e-04'}\n","{'epoch': 10, 'train_loss': '5.69e-04', 'valid_loss': '8.53e-04'}\n","{'epoch': 11, 'train_loss': '5.47e-04', 'valid_loss': '8.03e-04'}\n","{'epoch': 12, 'train_loss': '5.29e-04', 'valid_loss': '7.57e-04'}\n","{'epoch': 13, 'train_loss': '5.14e-04', 'valid_loss': '7.16e-04'}\n","{'epoch': 14, 'train_loss': '5.01e-04', 'valid_loss': '6.79e-04'}\n","{'epoch': 15, 'train_loss': '4.90e-04', 'valid_loss': '6.45e-04'}\n","{'epoch': 16, 'train_loss': '4.81e-04', 'valid_loss': '6.15e-04'}\n","{'epoch': 17, 'train_loss': '4.73e-04', 'valid_loss': '5.87e-04'}\n","{'epoch': 18, 'train_loss': '4.66e-04', 'valid_loss': '5.63e-04'}\n","{'epoch': 19, 'train_loss': '4.60e-04', 'valid_loss': '5.41e-04'}\n","{'epoch': 20, 'train_loss': '4.55e-04', 'valid_loss': '5.21e-04'}\n","{'epoch': 21, 'train_loss': '4.50e-04', 'valid_loss': '5.03e-04'}\n","{'epoch': 22, 'train_loss': '4.46e-04', 'valid_loss': '4.86e-04'}\n","{'epoch': 23, 'train_loss': '4.42e-04', 'valid_loss': '4.72e-04'}\n","{'epoch': 24, 'train_loss': '4.38e-04', 'valid_loss': '4.59e-04'}\n","{'epoch': 25, 'train_loss': '4.35e-04', 'valid_loss': '4.47e-04'}\n","{'epoch': 26, 'train_loss': '4.32e-04', 'valid_loss': '4.37e-04'}\n","{'epoch': 27, 'train_loss': '4.29e-04', 'valid_loss': '4.28e-04'}\n","{'epoch': 28, 'train_loss': '4.27e-04', 'valid_loss': '4.19e-04'}\n","{'epoch': 29, 'train_loss': '4.24e-04', 'valid_loss': '4.12e-04'}\n","{'epoch': 30, 'train_loss': '4.22e-04', 'valid_loss': '4.05e-04'}\n","{'epoch': 31, 'train_loss': '4.20e-04', 'valid_loss': '4.00e-04'}\n","{'epoch': 32, 'train_loss': '4.18e-04', 'valid_loss': '3.94e-04'}\n","{'epoch': 33, 'train_loss': '4.16e-04', 'valid_loss': '3.90e-04'}\n","{'epoch': 34, 'train_loss': '4.14e-04', 'valid_loss': '3.86e-04'}\n","{'epoch': 35, 'train_loss': '4.12e-04', 'valid_loss': '3.83e-04'}\n","{'epoch': 36, 'train_loss': '4.11e-04', 'valid_loss': '3.80e-04'}\n","{'epoch': 37, 'train_loss': '4.09e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 38, 'train_loss': '4.08e-04', 'valid_loss': '3.75e-04'}\n","{'epoch': 39, 'train_loss': '4.06e-04', 'valid_loss': '3.73e-04'}\n","{'epoch': 40, 'train_loss': '4.05e-04', 'valid_loss': '3.71e-04'}\n","{'epoch': 41, 'train_loss': '4.04e-04', 'valid_loss': '3.69e-04'}\n","{'epoch': 42, 'train_loss': '4.03e-04', 'valid_loss': '3.68e-04'}\n","{'epoch': 43, 'train_loss': '4.02e-04', 'valid_loss': '3.66e-04'}\n","{'epoch': 44, 'train_loss': '4.01e-04', 'valid_loss': '3.65e-04'}\n","{'epoch': 45, 'train_loss': '4.00e-04', 'valid_loss': '3.64e-04'}\n","{'epoch': 46, 'train_loss': '3.99e-04', 'valid_loss': '3.62e-04'}\n","{'epoch': 47, 'train_loss': '3.98e-04', 'valid_loss': '3.61e-04'}\n","{'epoch': 48, 'train_loss': '3.97e-04', 'valid_loss': '3.60e-04'}\n","{'epoch': 49, 'train_loss': '3.96e-04', 'valid_loss': '3.59e-04'}\n","{'epoch': 50, 'train_loss': '3.95e-04', 'valid_loss': '3.58e-04'}\n","{'epoch': 51, 'train_loss': '3.94e-04', 'valid_loss': '3.57e-04'}\n","{'epoch': 52, 'train_loss': '3.93e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 53, 'train_loss': '3.93e-04', 'valid_loss': '3.54e-04'}\n","{'epoch': 54, 'train_loss': '3.92e-04', 'valid_loss': '3.53e-04'}\n","{'epoch': 55, 'train_loss': '3.91e-04', 'valid_loss': '3.52e-04'}\n","{'epoch': 56, 'train_loss': '3.91e-04', 'valid_loss': '3.50e-04'}\n","{'epoch': 57, 'train_loss': '3.90e-04', 'valid_loss': '3.49e-04'}\n","{'epoch': 58, 'train_loss': '3.89e-04', 'valid_loss': '3.48e-04'}\n","{'epoch': 59, 'train_loss': '3.88e-04', 'valid_loss': '3.46e-04'}\n","{'epoch': 60, 'train_loss': '3.88e-04', 'valid_loss': '3.45e-04'}\n","{'epoch': 61, 'train_loss': '3.87e-04', 'valid_loss': '3.44e-04'}\n","{'epoch': 62, 'train_loss': '3.86e-04', 'valid_loss': '3.42e-04'}\n","{'epoch': 63, 'train_loss': '3.86e-04', 'valid_loss': '3.41e-04'}\n","{'epoch': 64, 'train_loss': '3.85e-04', 'valid_loss': '3.39e-04'}\n","{'epoch': 65, 'train_loss': '3.85e-04', 'valid_loss': '3.38e-04'}\n","{'epoch': 66, 'train_loss': '3.84e-04', 'valid_loss': '3.37e-04'}\n","{'epoch': 67, 'train_loss': '3.83e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 68, 'train_loss': '3.83e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 69, 'train_loss': '3.82e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 70, 'train_loss': '3.82e-04', 'valid_loss': '3.31e-04'}\n","{'epoch': 71, 'train_loss': '3.81e-04', 'valid_loss': '3.30e-04'}\n","{'epoch': 72, 'train_loss': '3.80e-04', 'valid_loss': '3.29e-04'}\n","{'epoch': 73, 'train_loss': '3.80e-04', 'valid_loss': '3.27e-04'}\n","{'epoch': 74, 'train_loss': '3.79e-04', 'valid_loss': '3.26e-04'}\n","{'epoch': 75, 'train_loss': '3.79e-04', 'valid_loss': '3.25e-04'}\n","{'epoch': 76, 'train_loss': '3.78e-04', 'valid_loss': '3.24e-04'}\n","{'epoch': 77, 'train_loss': '3.78e-04', 'valid_loss': '3.22e-04'}\n","{'epoch': 78, 'train_loss': '3.77e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 79, 'train_loss': '3.77e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 80, 'train_loss': '3.76e-04', 'valid_loss': '3.19e-04'}\n","{'epoch': 81, 'train_loss': '3.75e-04', 'valid_loss': '3.18e-04'}\n","{'epoch': 82, 'train_loss': '3.75e-04', 'valid_loss': '3.17e-04'}\n","{'epoch': 83, 'train_loss': '3.74e-04', 'valid_loss': '3.16e-04'}\n","{'epoch': 84, 'train_loss': '3.74e-04', 'valid_loss': '3.15e-04'}\n","{'epoch': 85, 'train_loss': '3.73e-04', 'valid_loss': '3.14e-04'}\n","{'epoch': 86, 'train_loss': '3.73e-04', 'valid_loss': '3.13e-04'}\n","{'epoch': 87, 'train_loss': '3.72e-04', 'valid_loss': '3.12e-04'}\n","{'epoch': 88, 'train_loss': '3.72e-04', 'valid_loss': '3.11e-04'}\n","{'epoch': 89, 'train_loss': '3.71e-04', 'valid_loss': '3.10e-04'}\n","{'epoch': 90, 'train_loss': '3.71e-04', 'valid_loss': '3.09e-04'}\n","{'epoch': 91, 'train_loss': '3.70e-04', 'valid_loss': '3.09e-04'}\n","{'epoch': 92, 'train_loss': '3.70e-04', 'valid_loss': '3.08e-04'}\n","{'epoch': 93, 'train_loss': '3.69e-04', 'valid_loss': '3.07e-04'}\n","{'epoch': 94, 'train_loss': '3.69e-04', 'valid_loss': '3.06e-04'}\n","{'epoch': 95, 'train_loss': '3.68e-04', 'valid_loss': '3.05e-04'}\n","{'epoch': 96, 'train_loss': '3.68e-04', 'valid_loss': '3.05e-04'}\n","{'epoch': 97, 'train_loss': '3.67e-04', 'valid_loss': '3.04e-04'}\n","{'epoch': 98, 'train_loss': '3.67e-04', 'valid_loss': '3.03e-04'}\n","{'epoch': 99, 'train_loss': '3.66e-04', 'valid_loss': '3.03e-04'}\n","best score = 3.03e-04\n"]}]},{"cell_type":"markdown","metadata":{"id":"1X_shzdXBflW"},"source":["For Adam optimizer, we also tried the learning rate = 0.1, 0.01, 0.001, and 0.0001. Speaking of the result, lr = 0.0001 gives the best result\n","\n","For Adam optimizer, we also tried the weight decay = 0.8, 0.85 and 0.9. Speaking of the result, no decay is the best match\n","\n","The best loss gained from Adam ( without changing batch size.etc) is 3.03e-04"]},{"cell_type":"markdown","source":["Hyperparameter: changing hidden size."],"metadata":{"id":"DxTBh0EODV9F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCfUu_L-BflX","executionInfo":{"status":"ok","timestamp":1669771047665,"user_tz":360,"elapsed":26858,"user":{"displayName":"Yulin Zhao","userId":"03352462298465772415"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"633ec81a-fa5b-4f96-f0c2-9365ee0cd7ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '3.61e-03', 'valid_loss': '1.00e-03'}\n","{'epoch': 1, 'train_loss': '6.17e-04', 'valid_loss': '8.17e-04'}\n","{'epoch': 2, 'train_loss': '5.59e-04', 'valid_loss': '7.22e-04'}\n","{'epoch': 3, 'train_loss': '5.17e-04', 'valid_loss': '6.52e-04'}\n","{'epoch': 4, 'train_loss': '4.88e-04', 'valid_loss': '5.89e-04'}\n","{'epoch': 5, 'train_loss': '4.66e-04', 'valid_loss': '5.37e-04'}\n","{'epoch': 6, 'train_loss': '4.50e-04', 'valid_loss': '4.98e-04'}\n","{'epoch': 7, 'train_loss': '4.38e-04', 'valid_loss': '4.67e-04'}\n","{'epoch': 8, 'train_loss': '4.28e-04', 'valid_loss': '4.43e-04'}\n","{'epoch': 9, 'train_loss': '4.21e-04', 'valid_loss': '4.24e-04'}\n","{'epoch': 10, 'train_loss': '4.14e-04', 'valid_loss': '4.09e-04'}\n","{'epoch': 11, 'train_loss': '4.09e-04', 'valid_loss': '3.96e-04'}\n","{'epoch': 12, 'train_loss': '4.04e-04', 'valid_loss': '3.85e-04'}\n","{'epoch': 13, 'train_loss': '4.00e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 14, 'train_loss': '3.96e-04', 'valid_loss': '3.68e-04'}\n","{'epoch': 15, 'train_loss': '3.93e-04', 'valid_loss': '3.61e-04'}\n","{'epoch': 16, 'train_loss': '3.90e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 17, 'train_loss': '3.88e-04', 'valid_loss': '3.49e-04'}\n","{'epoch': 18, 'train_loss': '3.86e-04', 'valid_loss': '3.45e-04'}\n","{'epoch': 19, 'train_loss': '3.84e-04', 'valid_loss': '3.40e-04'}\n","{'epoch': 20, 'train_loss': '3.82e-04', 'valid_loss': '3.37e-04'}\n","{'epoch': 21, 'train_loss': '3.81e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 22, 'train_loss': '3.79e-04', 'valid_loss': '3.31e-04'}\n","{'epoch': 23, 'train_loss': '3.78e-04', 'valid_loss': '3.28e-04'}\n","{'epoch': 24, 'train_loss': '3.77e-04', 'valid_loss': '3.26e-04'}\n","{'epoch': 25, 'train_loss': '3.76e-04', 'valid_loss': '3.25e-04'}\n","{'epoch': 26, 'train_loss': '3.75e-04', 'valid_loss': '3.23e-04'}\n","{'epoch': 27, 'train_loss': '3.74e-04', 'valid_loss': '3.22e-04'}\n","{'epoch': 28, 'train_loss': '3.74e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 29, 'train_loss': '3.73e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 30, 'train_loss': '3.72e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 31, 'train_loss': '3.71e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 32, 'train_loss': '3.70e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 33, 'train_loss': '3.70e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 34, 'train_loss': '3.69e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 35, 'train_loss': '3.68e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 36, 'train_loss': '3.67e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 37, 'train_loss': '3.66e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 38, 'train_loss': '3.66e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 39, 'train_loss': '3.65e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 40, 'train_loss': '3.64e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 41, 'train_loss': '3.64e-04', 'valid_loss': '3.21e-04'}\n","{'epoch': 42, 'train_loss': '3.63e-04', 'valid_loss': '3.21e-04'}\n","best score = 3.20e-04\n"]}],"source":["model = Model(hidden_size=64)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Hyperparameter: number of layers"],"metadata":{"id":"9JhE0kHIDdVH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XDLwhsSBflY","executionInfo":{"status":"ok","timestamp":1669771120896,"user_tz":360,"elapsed":73256,"user":{"displayName":"Yulin Zhao","userId":"03352462298465772415"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a187fd60-7dcf-4158-d41d-cab8e8dcce51"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '1.16e-02', 'valid_loss': '6.57e-03'}\n","{'epoch': 1, 'train_loss': '3.55e-03', 'valid_loss': '2.12e-03'}\n","{'epoch': 2, 'train_loss': '1.33e-03', 'valid_loss': '1.10e-03'}\n","{'epoch': 3, 'train_loss': '9.75e-04', 'valid_loss': '9.33e-04'}\n","{'epoch': 4, 'train_loss': '8.86e-04', 'valid_loss': '8.64e-04'}\n","{'epoch': 5, 'train_loss': '8.25e-04', 'valid_loss': '8.09e-04'}\n","{'epoch': 6, 'train_loss': '7.72e-04', 'valid_loss': '7.61e-04'}\n","{'epoch': 7, 'train_loss': '7.26e-04', 'valid_loss': '7.18e-04'}\n","{'epoch': 8, 'train_loss': '6.85e-04', 'valid_loss': '6.80e-04'}\n","{'epoch': 9, 'train_loss': '6.48e-04', 'valid_loss': '6.47e-04'}\n","{'epoch': 10, 'train_loss': '6.17e-04', 'valid_loss': '6.18e-04'}\n","{'epoch': 11, 'train_loss': '5.88e-04', 'valid_loss': '5.92e-04'}\n","{'epoch': 12, 'train_loss': '5.64e-04', 'valid_loss': '5.69e-04'}\n","{'epoch': 13, 'train_loss': '5.42e-04', 'valid_loss': '5.49e-04'}\n","{'epoch': 14, 'train_loss': '5.23e-04', 'valid_loss': '5.31e-04'}\n","{'epoch': 15, 'train_loss': '5.06e-04', 'valid_loss': '5.16e-04'}\n","{'epoch': 16, 'train_loss': '4.92e-04', 'valid_loss': '5.02e-04'}\n","{'epoch': 17, 'train_loss': '4.79e-04', 'valid_loss': '4.90e-04'}\n","{'epoch': 18, 'train_loss': '4.68e-04', 'valid_loss': '4.80e-04'}\n","{'epoch': 19, 'train_loss': '4.59e-04', 'valid_loss': '4.71e-04'}\n","{'epoch': 20, 'train_loss': '4.51e-04', 'valid_loss': '4.63e-04'}\n","{'epoch': 21, 'train_loss': '4.44e-04', 'valid_loss': '4.57e-04'}\n","{'epoch': 22, 'train_loss': '4.38e-04', 'valid_loss': '4.51e-04'}\n","{'epoch': 23, 'train_loss': '4.33e-04', 'valid_loss': '4.45e-04'}\n","{'epoch': 24, 'train_loss': '4.29e-04', 'valid_loss': '4.41e-04'}\n","{'epoch': 25, 'train_loss': '4.25e-04', 'valid_loss': '4.36e-04'}\n","{'epoch': 26, 'train_loss': '4.21e-04', 'valid_loss': '4.32e-04'}\n","{'epoch': 27, 'train_loss': '4.19e-04', 'valid_loss': '4.28e-04'}\n","{'epoch': 28, 'train_loss': '4.16e-04', 'valid_loss': '4.25e-04'}\n","{'epoch': 29, 'train_loss': '4.14e-04', 'valid_loss': '4.21e-04'}\n","{'epoch': 30, 'train_loss': '4.12e-04', 'valid_loss': '4.18e-04'}\n","{'epoch': 31, 'train_loss': '4.10e-04', 'valid_loss': '4.15e-04'}\n","{'epoch': 32, 'train_loss': '4.08e-04', 'valid_loss': '4.12e-04'}\n","{'epoch': 33, 'train_loss': '4.07e-04', 'valid_loss': '4.09e-04'}\n","{'epoch': 34, 'train_loss': '4.05e-04', 'valid_loss': '4.06e-04'}\n","{'epoch': 35, 'train_loss': '4.04e-04', 'valid_loss': '4.03e-04'}\n","{'epoch': 36, 'train_loss': '4.03e-04', 'valid_loss': '4.01e-04'}\n","{'epoch': 37, 'train_loss': '4.01e-04', 'valid_loss': '3.98e-04'}\n","{'epoch': 38, 'train_loss': '4.00e-04', 'valid_loss': '3.96e-04'}\n","{'epoch': 39, 'train_loss': '3.99e-04', 'valid_loss': '3.94e-04'}\n","{'epoch': 40, 'train_loss': '3.98e-04', 'valid_loss': '3.92e-04'}\n","{'epoch': 41, 'train_loss': '3.97e-04', 'valid_loss': '3.90e-04'}\n","{'epoch': 42, 'train_loss': '3.96e-04', 'valid_loss': '3.88e-04'}\n","{'epoch': 43, 'train_loss': '3.95e-04', 'valid_loss': '3.86e-04'}\n","{'epoch': 44, 'train_loss': '3.94e-04', 'valid_loss': '3.85e-04'}\n","{'epoch': 45, 'train_loss': '3.93e-04', 'valid_loss': '3.83e-04'}\n","{'epoch': 46, 'train_loss': '3.92e-04', 'valid_loss': '3.82e-04'}\n","{'epoch': 47, 'train_loss': '3.92e-04', 'valid_loss': '3.80e-04'}\n","{'epoch': 48, 'train_loss': '3.91e-04', 'valid_loss': '3.79e-04'}\n","{'epoch': 49, 'train_loss': '3.90e-04', 'valid_loss': '3.78e-04'}\n","{'epoch': 50, 'train_loss': '3.89e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 51, 'train_loss': '3.88e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 52, 'train_loss': '3.88e-04', 'valid_loss': '3.75e-04'}\n","{'epoch': 53, 'train_loss': '3.87e-04', 'valid_loss': '3.74e-04'}\n","{'epoch': 54, 'train_loss': '3.86e-04', 'valid_loss': '3.73e-04'}\n","{'epoch': 55, 'train_loss': '3.86e-04', 'valid_loss': '3.72e-04'}\n","{'epoch': 56, 'train_loss': '3.85e-04', 'valid_loss': '3.72e-04'}\n","{'epoch': 57, 'train_loss': '3.84e-04', 'valid_loss': '3.71e-04'}\n","{'epoch': 58, 'train_loss': '3.84e-04', 'valid_loss': '3.70e-04'}\n","{'epoch': 59, 'train_loss': '3.83e-04', 'valid_loss': '3.70e-04'}\n","{'epoch': 60, 'train_loss': '3.82e-04', 'valid_loss': '3.69e-04'}\n","{'epoch': 61, 'train_loss': '3.82e-04', 'valid_loss': '3.68e-04'}\n","{'epoch': 62, 'train_loss': '3.81e-04', 'valid_loss': '3.68e-04'}\n","{'epoch': 63, 'train_loss': '3.81e-04', 'valid_loss': '3.67e-04'}\n","{'epoch': 64, 'train_loss': '3.80e-04', 'valid_loss': '3.67e-04'}\n","{'epoch': 65, 'train_loss': '3.80e-04', 'valid_loss': '3.66e-04'}\n","{'epoch': 66, 'train_loss': '3.79e-04', 'valid_loss': '3.66e-04'}\n","{'epoch': 67, 'train_loss': '3.79e-04', 'valid_loss': '3.65e-04'}\n","{'epoch': 68, 'train_loss': '3.78e-04', 'valid_loss': '3.65e-04'}\n","{'epoch': 69, 'train_loss': '3.77e-04', 'valid_loss': '3.64e-04'}\n","{'epoch': 70, 'train_loss': '3.77e-04', 'valid_loss': '3.64e-04'}\n","{'epoch': 71, 'train_loss': '3.76e-04', 'valid_loss': '3.63e-04'}\n","{'epoch': 72, 'train_loss': '3.76e-04', 'valid_loss': '3.63e-04'}\n","{'epoch': 73, 'train_loss': '3.75e-04', 'valid_loss': '3.62e-04'}\n","{'epoch': 74, 'train_loss': '3.75e-04', 'valid_loss': '3.62e-04'}\n","{'epoch': 75, 'train_loss': '3.74e-04', 'valid_loss': '3.61e-04'}\n","{'epoch': 76, 'train_loss': '3.74e-04', 'valid_loss': '3.61e-04'}\n","{'epoch': 77, 'train_loss': '3.74e-04', 'valid_loss': '3.60e-04'}\n","{'epoch': 78, 'train_loss': '3.73e-04', 'valid_loss': '3.60e-04'}\n","{'epoch': 79, 'train_loss': '3.73e-04', 'valid_loss': '3.60e-04'}\n","{'epoch': 80, 'train_loss': '3.72e-04', 'valid_loss': '3.59e-04'}\n","{'epoch': 81, 'train_loss': '3.72e-04', 'valid_loss': '3.59e-04'}\n","{'epoch': 82, 'train_loss': '3.71e-04', 'valid_loss': '3.58e-04'}\n","{'epoch': 83, 'train_loss': '3.71e-04', 'valid_loss': '3.58e-04'}\n","{'epoch': 84, 'train_loss': '3.70e-04', 'valid_loss': '3.57e-04'}\n","{'epoch': 85, 'train_loss': '3.70e-04', 'valid_loss': '3.57e-04'}\n","{'epoch': 86, 'train_loss': '3.69e-04', 'valid_loss': '3.56e-04'}\n","{'epoch': 87, 'train_loss': '3.69e-04', 'valid_loss': '3.56e-04'}\n","{'epoch': 88, 'train_loss': '3.68e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 89, 'train_loss': '3.68e-04', 'valid_loss': '3.55e-04'}\n","{'epoch': 90, 'train_loss': '3.68e-04', 'valid_loss': '3.54e-04'}\n","{'epoch': 91, 'train_loss': '3.67e-04', 'valid_loss': '3.54e-04'}\n","{'epoch': 92, 'train_loss': '3.67e-04', 'valid_loss': '3.53e-04'}\n","{'epoch': 93, 'train_loss': '3.66e-04', 'valid_loss': '3.53e-04'}\n","{'epoch': 94, 'train_loss': '3.66e-04', 'valid_loss': '3.52e-04'}\n","{'epoch': 95, 'train_loss': '3.65e-04', 'valid_loss': '3.52e-04'}\n","{'epoch': 96, 'train_loss': '3.65e-04', 'valid_loss': '3.52e-04'}\n","{'epoch': 97, 'train_loss': '3.65e-04', 'valid_loss': '3.51e-04'}\n","{'epoch': 98, 'train_loss': '3.64e-04', 'valid_loss': '3.51e-04'}\n","{'epoch': 99, 'train_loss': '3.64e-04', 'valid_loss': '3.50e-04'}\n","best score = 3.50e-04\n"]}],"source":["model = Model(num_layers=3)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Hyperparameter: changing dropout rate."],"metadata":{"id":"_KROYjv2D-_X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"35Rn0P1DBflZ","executionInfo":{"status":"ok","timestamp":1669771146669,"user_tz":360,"elapsed":25810,"user":{"displayName":"Yulin Zhao","userId":"03352462298465772415"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"48f519bc-447b-4a9f-fa3a-7a4ee95bb4f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '8.43e-03', 'valid_loss': '4.26e-03'}\n","{'epoch': 1, 'train_loss': '3.13e-03', 'valid_loss': '1.51e-03'}\n","{'epoch': 2, 'train_loss': '1.72e-03', 'valid_loss': '9.59e-04'}\n","{'epoch': 3, 'train_loss': '1.41e-03', 'valid_loss': '8.47e-04'}\n","{'epoch': 4, 'train_loss': '1.26e-03', 'valid_loss': '7.90e-04'}\n","{'epoch': 5, 'train_loss': '1.15e-03', 'valid_loss': '7.47e-04'}\n","{'epoch': 6, 'train_loss': '1.06e-03', 'valid_loss': '7.11e-04'}\n","{'epoch': 7, 'train_loss': '9.76e-04', 'valid_loss': '6.80e-04'}\n","{'epoch': 8, 'train_loss': '9.08e-04', 'valid_loss': '6.54e-04'}\n","{'epoch': 9, 'train_loss': '8.49e-04', 'valid_loss': '6.30e-04'}\n","{'epoch': 10, 'train_loss': '7.98e-04', 'valid_loss': '6.08e-04'}\n","{'epoch': 11, 'train_loss': '7.53e-04', 'valid_loss': '5.89e-04'}\n","{'epoch': 12, 'train_loss': '7.14e-04', 'valid_loss': '5.71e-04'}\n","{'epoch': 13, 'train_loss': '6.80e-04', 'valid_loss': '5.54e-04'}\n","{'epoch': 14, 'train_loss': '6.49e-04', 'valid_loss': '5.39e-04'}\n","{'epoch': 15, 'train_loss': '6.22e-04', 'valid_loss': '5.25e-04'}\n","{'epoch': 16, 'train_loss': '5.98e-04', 'valid_loss': '5.11e-04'}\n","{'epoch': 17, 'train_loss': '5.78e-04', 'valid_loss': '4.99e-04'}\n","{'epoch': 18, 'train_loss': '5.59e-04', 'valid_loss': '4.87e-04'}\n","{'epoch': 19, 'train_loss': '5.43e-04', 'valid_loss': '4.76e-04'}\n","{'epoch': 20, 'train_loss': '5.28e-04', 'valid_loss': '4.66e-04'}\n","{'epoch': 21, 'train_loss': '5.15e-04', 'valid_loss': '4.56e-04'}\n","{'epoch': 22, 'train_loss': '5.04e-04', 'valid_loss': '4.47e-04'}\n","{'epoch': 23, 'train_loss': '4.94e-04', 'valid_loss': '4.39e-04'}\n","{'epoch': 24, 'train_loss': '4.85e-04', 'valid_loss': '4.31e-04'}\n","{'epoch': 25, 'train_loss': '4.77e-04', 'valid_loss': '4.24e-04'}\n","{'epoch': 26, 'train_loss': '4.70e-04', 'valid_loss': '4.18e-04'}\n","{'epoch': 27, 'train_loss': '4.64e-04', 'valid_loss': '4.12e-04'}\n","{'epoch': 28, 'train_loss': '4.59e-04', 'valid_loss': '4.06e-04'}\n","{'epoch': 29, 'train_loss': '4.53e-04', 'valid_loss': '4.02e-04'}\n","{'epoch': 30, 'train_loss': '4.49e-04', 'valid_loss': '3.97e-04'}\n","{'epoch': 31, 'train_loss': '4.45e-04', 'valid_loss': '3.94e-04'}\n","{'epoch': 32, 'train_loss': '4.41e-04', 'valid_loss': '3.90e-04'}\n","{'epoch': 33, 'train_loss': '4.37e-04', 'valid_loss': '3.87e-04'}\n","{'epoch': 34, 'train_loss': '4.34e-04', 'valid_loss': '3.85e-04'}\n","{'epoch': 35, 'train_loss': '4.31e-04', 'valid_loss': '3.83e-04'}\n","{'epoch': 36, 'train_loss': '4.28e-04', 'valid_loss': '3.81e-04'}\n","{'epoch': 37, 'train_loss': '4.25e-04', 'valid_loss': '3.79e-04'}\n","{'epoch': 38, 'train_loss': '4.23e-04', 'valid_loss': '3.78e-04'}\n","{'epoch': 39, 'train_loss': '4.20e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 40, 'train_loss': '4.18e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 41, 'train_loss': '4.16e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 42, 'train_loss': '4.14e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 43, 'train_loss': '4.12e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 44, 'train_loss': '4.10e-04', 'valid_loss': '3.76e-04'}\n","{'epoch': 45, 'train_loss': '4.08e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 46, 'train_loss': '4.06e-04', 'valid_loss': '3.77e-04'}\n","{'epoch': 47, 'train_loss': '4.05e-04', 'valid_loss': '3.78e-04'}\n","{'epoch': 48, 'train_loss': '4.03e-04', 'valid_loss': '3.78e-04'}\n","{'epoch': 49, 'train_loss': '4.02e-04', 'valid_loss': '3.79e-04'}\n","{'epoch': 50, 'train_loss': '4.00e-04', 'valid_loss': '3.80e-04'}\n","{'epoch': 51, 'train_loss': '3.99e-04', 'valid_loss': '3.81e-04'}\n","{'epoch': 52, 'train_loss': '3.98e-04', 'valid_loss': '3.82e-04'}\n","best score = 3.76e-04\n"]}],"source":["model = Model(dropout=0.3)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Combining optimimization (best model we currently have)."],"metadata":{"id":"TwL4cApiEOmg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE9VadvfBflb","executionInfo":{"status":"ok","timestamp":1669771234016,"user_tz":360,"elapsed":87356,"user":{"displayName":"Yulin Zhao","userId":"03352462298465772415"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c125aaa1-5478-4c31-ee39-042fee5a8558"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'epoch': 0, 'train_loss': '6.80e-03', 'valid_loss': '2.46e-03'}\n","{'epoch': 1, 'train_loss': '1.49e-03', 'valid_loss': '1.00e-03'}\n","{'epoch': 2, 'train_loss': '1.06e-03', 'valid_loss': '9.33e-04'}\n","{'epoch': 3, 'train_loss': '9.48e-04', 'valid_loss': '8.52e-04'}\n","{'epoch': 4, 'train_loss': '8.50e-04', 'valid_loss': '7.87e-04'}\n","{'epoch': 5, 'train_loss': '7.68e-04', 'valid_loss': '7.29e-04'}\n","{'epoch': 6, 'train_loss': '7.00e-04', 'valid_loss': '6.79e-04'}\n","{'epoch': 7, 'train_loss': '6.42e-04', 'valid_loss': '6.34e-04'}\n","{'epoch': 8, 'train_loss': '5.93e-04', 'valid_loss': '5.93e-04'}\n","{'epoch': 9, 'train_loss': '5.51e-04', 'valid_loss': '5.55e-04'}\n","{'epoch': 10, 'train_loss': '5.17e-04', 'valid_loss': '5.21e-04'}\n","{'epoch': 11, 'train_loss': '4.88e-04', 'valid_loss': '4.89e-04'}\n","{'epoch': 12, 'train_loss': '4.64e-04', 'valid_loss': '4.61e-04'}\n","{'epoch': 13, 'train_loss': '4.46e-04', 'valid_loss': '4.37e-04'}\n","{'epoch': 14, 'train_loss': '4.31e-04', 'valid_loss': '4.16e-04'}\n","{'epoch': 15, 'train_loss': '4.20e-04', 'valid_loss': '3.99e-04'}\n","{'epoch': 16, 'train_loss': '4.12e-04', 'valid_loss': '3.86e-04'}\n","{'epoch': 17, 'train_loss': '4.07e-04', 'valid_loss': '3.75e-04'}\n","{'epoch': 18, 'train_loss': '4.02e-04', 'valid_loss': '3.68e-04'}\n","{'epoch': 19, 'train_loss': '3.99e-04', 'valid_loss': '3.62e-04'}\n","{'epoch': 20, 'train_loss': '3.96e-04', 'valid_loss': '3.58e-04'}\n","{'epoch': 21, 'train_loss': '3.94e-04', 'valid_loss': '3.54e-04'}\n","{'epoch': 22, 'train_loss': '3.92e-04', 'valid_loss': '3.52e-04'}\n","{'epoch': 23, 'train_loss': '3.91e-04', 'valid_loss': '3.49e-04'}\n","{'epoch': 24, 'train_loss': '3.89e-04', 'valid_loss': '3.48e-04'}\n","{'epoch': 25, 'train_loss': '3.88e-04', 'valid_loss': '3.46e-04'}\n","{'epoch': 26, 'train_loss': '3.87e-04', 'valid_loss': '3.45e-04'}\n","{'epoch': 27, 'train_loss': '3.85e-04', 'valid_loss': '3.44e-04'}\n","{'epoch': 28, 'train_loss': '3.84e-04', 'valid_loss': '3.43e-04'}\n","{'epoch': 29, 'train_loss': '3.83e-04', 'valid_loss': '3.42e-04'}\n","{'epoch': 30, 'train_loss': '3.82e-04', 'valid_loss': '3.42e-04'}\n","{'epoch': 31, 'train_loss': '3.81e-04', 'valid_loss': '3.41e-04'}\n","{'epoch': 32, 'train_loss': '3.80e-04', 'valid_loss': '3.41e-04'}\n","{'epoch': 33, 'train_loss': '3.79e-04', 'valid_loss': '3.40e-04'}\n","{'epoch': 34, 'train_loss': '3.79e-04', 'valid_loss': '3.39e-04'}\n","{'epoch': 35, 'train_loss': '3.78e-04', 'valid_loss': '3.39e-04'}\n","{'epoch': 36, 'train_loss': '3.77e-04', 'valid_loss': '3.38e-04'}\n","{'epoch': 37, 'train_loss': '3.76e-04', 'valid_loss': '3.37e-04'}\n","{'epoch': 38, 'train_loss': '3.76e-04', 'valid_loss': '3.36e-04'}\n","{'epoch': 39, 'train_loss': '3.75e-04', 'valid_loss': '3.35e-04'}\n","{'epoch': 40, 'train_loss': '3.74e-04', 'valid_loss': '3.34e-04'}\n","{'epoch': 41, 'train_loss': '3.73e-04', 'valid_loss': '3.33e-04'}\n","{'epoch': 42, 'train_loss': '3.73e-04', 'valid_loss': '3.32e-04'}\n","{'epoch': 43, 'train_loss': '3.72e-04', 'valid_loss': '3.30e-04'}\n","{'epoch': 44, 'train_loss': '3.71e-04', 'valid_loss': '3.29e-04'}\n","{'epoch': 45, 'train_loss': '3.71e-04', 'valid_loss': '3.28e-04'}\n","{'epoch': 46, 'train_loss': '3.70e-04', 'valid_loss': '3.26e-04'}\n","{'epoch': 47, 'train_loss': '3.69e-04', 'valid_loss': '3.25e-04'}\n","{'epoch': 48, 'train_loss': '3.69e-04', 'valid_loss': '3.23e-04'}\n","{'epoch': 49, 'train_loss': '3.68e-04', 'valid_loss': '3.22e-04'}\n","{'epoch': 50, 'train_loss': '3.67e-04', 'valid_loss': '3.20e-04'}\n","{'epoch': 51, 'train_loss': '3.67e-04', 'valid_loss': '3.19e-04'}\n","{'epoch': 52, 'train_loss': '3.66e-04', 'valid_loss': '3.17e-04'}\n","{'epoch': 53, 'train_loss': '3.65e-04', 'valid_loss': '3.16e-04'}\n","{'epoch': 54, 'train_loss': '3.65e-04', 'valid_loss': '3.15e-04'}\n","{'epoch': 55, 'train_loss': '3.64e-04', 'valid_loss': '3.13e-04'}\n","{'epoch': 56, 'train_loss': '3.64e-04', 'valid_loss': '3.12e-04'}\n","{'epoch': 57, 'train_loss': '3.63e-04', 'valid_loss': '3.10e-04'}\n","{'epoch': 58, 'train_loss': '3.63e-04', 'valid_loss': '3.09e-04'}\n","{'epoch': 59, 'train_loss': '3.62e-04', 'valid_loss': '3.08e-04'}\n","{'epoch': 60, 'train_loss': '3.62e-04', 'valid_loss': '3.07e-04'}\n","{'epoch': 61, 'train_loss': '3.61e-04', 'valid_loss': '3.05e-04'}\n","{'epoch': 62, 'train_loss': '3.61e-04', 'valid_loss': '3.04e-04'}\n","{'epoch': 63, 'train_loss': '3.60e-04', 'valid_loss': '3.03e-04'}\n","{'epoch': 64, 'train_loss': '3.60e-04', 'valid_loss': '3.02e-04'}\n","{'epoch': 65, 'train_loss': '3.59e-04', 'valid_loss': '3.01e-04'}\n","{'epoch': 66, 'train_loss': '3.59e-04', 'valid_loss': '3.00e-04'}\n","{'epoch': 67, 'train_loss': '3.58e-04', 'valid_loss': '2.99e-04'}\n","{'epoch': 68, 'train_loss': '3.58e-04', 'valid_loss': '2.98e-04'}\n","{'epoch': 69, 'train_loss': '3.57e-04', 'valid_loss': '2.98e-04'}\n","{'epoch': 70, 'train_loss': '3.57e-04', 'valid_loss': '2.97e-04'}\n","{'epoch': 71, 'train_loss': '3.57e-04', 'valid_loss': '2.96e-04'}\n","{'epoch': 72, 'train_loss': '3.56e-04', 'valid_loss': '2.95e-04'}\n","{'epoch': 73, 'train_loss': '3.56e-04', 'valid_loss': '2.95e-04'}\n","{'epoch': 74, 'train_loss': '3.55e-04', 'valid_loss': '2.94e-04'}\n","{'epoch': 75, 'train_loss': '3.55e-04', 'valid_loss': '2.94e-04'}\n","{'epoch': 76, 'train_loss': '3.54e-04', 'valid_loss': '2.93e-04'}\n","{'epoch': 77, 'train_loss': '3.54e-04', 'valid_loss': '2.93e-04'}\n","{'epoch': 78, 'train_loss': '3.53e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 79, 'train_loss': '3.53e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 80, 'train_loss': '3.53e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 81, 'train_loss': '3.52e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 82, 'train_loss': '3.52e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 83, 'train_loss': '3.51e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 84, 'train_loss': '3.51e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 85, 'train_loss': '3.50e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 86, 'train_loss': '3.50e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 87, 'train_loss': '3.49e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 88, 'train_loss': '3.49e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 89, 'train_loss': '3.49e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 90, 'train_loss': '3.48e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 91, 'train_loss': '3.48e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 92, 'train_loss': '3.47e-04', 'valid_loss': '2.91e-04'}\n","{'epoch': 93, 'train_loss': '3.47e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 94, 'train_loss': '3.46e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 95, 'train_loss': '3.46e-04', 'valid_loss': '2.92e-04'}\n","{'epoch': 96, 'train_loss': '3.45e-04', 'valid_loss': '2.92e-04'}\n","best score = 2.91e-04\n"]}],"source":["model = Model(hidden_size=64, num_layers=3, dropout=0.3)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","loss_function = nn.MSELoss()\n","\n","min_loss = float('inf')\n","count = 0\n","\n","for epoch in range(100):\n","    train_loss = 0.0\n","\n","    for i in range(0, len(train_X), 16):\n","        output = model(torch.from_numpy(train_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(train_y[i:i+16]).float())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    train_loss /= (len(train_X)//16)\n","\n","    # validation\n","    with torch.no_grad():\n","        valid_loss = 0.0\n","        for i in range(0, len(valid_X), 16):\n","            output = model(torch.from_numpy(valid_X[i:i+16]).float())\n","            loss = loss_function(output, torch.from_numpy(valid_y[i:i+16]).float())\n","            valid_loss += loss.item()\n","    valid_loss /= (len(valid_X)//16)\n","\n","    print({ 'epoch': epoch, 'train_loss': '{:.2e}'.format(train_loss), \n","    'valid_loss': '{:.2e}'.format(valid_loss),})\n","\n","    # early stopping\n","    if valid_loss > min_loss:\n","        count += 1\n","        if count > 9:\n","            break\n","    else:\n","        min_loss = valid_loss\n","        count = 0\n","        torch.save(model, 'best_model')\n","        \n","print(f'best score = {min_loss:.2e}')"]},{"cell_type":"markdown","source":["Summary."],"metadata":{"id":"kJn40Qp3EZEu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtOaMGQSBflc","executionInfo":{"status":"ok","timestamp":1669771234182,"user_tz":360,"elapsed":173,"user":{"displayName":"Yulin Zhao","userId":"03352462298465772415"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f737c02f-5fb9-41eb-87ad-de24d4f0632b"},"outputs":[{"output_type":"stream","name":"stdout","text":["test loss = 1.86e-03\n"]}],"source":["model = torch.load('best_model')\n","with torch.no_grad():\n","    test_loss = 0.0\n","    for i in range(0, len(test_X), 16):\n","        output = model(torch.from_numpy(test_X[i:i+16]).float())\n","        loss = loss_function(output, torch.from_numpy(test_y[i:i+16]).float())\n","        test_loss += loss.item()\n","test_loss /= (len(test_X)//16)\n","print(f'test loss = {test_loss:.2e}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmfM4AAlBfld"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}